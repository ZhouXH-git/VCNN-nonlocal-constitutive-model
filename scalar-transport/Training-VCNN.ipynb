{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b1e52b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN Architecture: m'=4 Embedding: {7,32,64,64} Fitting:{256,128,1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8872eaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f204f8eb610>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# system modules\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Math\n",
    "\n",
    "# scientific computing\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import pandas as pd\n",
    "np.random.seed(42)\n",
    "\n",
    "# plotting\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "# from plotly.offline import iplot, init_notebook_mode\n",
    "# import plotly.graph_objs as go\n",
    "# import plotly.io as pio\n",
    "# from plotly import subplots\n",
    "# init_notebook_mode(connected=True)\n",
    "\n",
    "# pytorch importing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torch.optim import lr_scheduler, Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c9c8cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(7,32)\n",
    "        self.fc2 = nn.Linear(32,64)\n",
    "        self.fc3 = nn.Linear(64,64)\n",
    "        \n",
    "        self.fc4 = nn.Linear(256,128)\n",
    "        self.fc5 = nn.Linear(128,1)\n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        R1 = X           # Batchsize * stencil_size * n_features\n",
    "        stencil = R1.shape[1]\n",
    "        R2 = X[:,:,4:11] \n",
    "        G1 = self.relu(self.fc1(R2))\n",
    "        G1 = self.relu(self.fc2(G1))\n",
    "        G1 = self.fc3(G1)\n",
    "        G2 = G1[:,:,0:4]\n",
    "        \n",
    "        G1t = G1.permute(0,2,1)\n",
    "        R1t = R1.permute(0,2,1)\n",
    "        D1 = torch.bmm(G1t,R1)/stencil\n",
    "        D2 = torch.bmm(R1t,G2)/stencil\n",
    "        D = torch.bmm(D1,D2)   # D = G1t*R*Rt*G2\n",
    "        \n",
    "        Dp = D.reshape(D.shape[0],-1)\n",
    "        out = self.relu(self.fc4(Dp))\n",
    "        out = self.fc5(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8562b8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, valid_loader, num_epoch):\n",
    "    train_err_hist = torch.cuda.FloatTensor(1,1).fill_(0)\n",
    "    valid_err_hist = torch.cuda.FloatTensor(1,1).fill_(0)\n",
    "    train_loss_hist = torch.cuda.FloatTensor(1,1).fill_(0)\n",
    "    valid_loss_hist = torch.cuda.FloatTensor(1,1).fill_(0)\n",
    "\n",
    "    for epoch in range(num_epoch+1):\n",
    "        train_loss_array = torch.cuda.FloatTensor(1,1).fill_(0)\n",
    "        train_err_rate_num = torch.cuda.FloatTensor(1,1).fill_(0)\n",
    "        train_err_rate_den = torch.cuda.FloatTensor(1,1).fill_(0)\n",
    "        valid_loss_array = torch.cuda.FloatTensor(1,1).fill_(0)\n",
    "        valid_err_rate_num = torch.cuda.FloatTensor(1,1).fill_(0)\n",
    "        valid_err_rate_den = torch.cuda.FloatTensor(1,1).fill_(0)\n",
    "\n",
    "        for i, data in enumerate(train_loader):\n",
    "            features, target = data\n",
    "            optimizer.zero_grad()\n",
    "            forward = model(features)\n",
    "            loss = loss_fn(forward, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss_array = torch.cat((train_loss_array, torch.cuda.FloatTensor([[loss.item()]])))\n",
    "            train_err_num, train_err_den = report_err_rate(target, forward)\n",
    "            train_err_rate_num = torch.cat((train_err_rate_num, (train_err_num.view(1,-1))**2), 0)\n",
    "            train_err_rate_den = torch.cat((train_err_rate_den, (train_err_den.view(1,-1))**2), 0)\n",
    "\n",
    "        train_loss = torch.mean(train_loss_array)\n",
    "        train_err_rate = 100*((torch.sum(train_err_rate_num, 0))**0.5)/((torch.sum(train_err_rate_den, 0))**0.5)\n",
    "\n",
    "        exp_lr_scheduler.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, data_valid in enumerate(valid_loader):\n",
    "                features_valid, target_valid = data_valid\n",
    "                forward_valid = model(features_valid)\n",
    "                pred_loss = loss_fn(forward_valid, target_valid)\n",
    "\n",
    "                valid_loss_array = torch.cat((valid_loss_array, torch.cuda.FloatTensor([[loss.item()]])))\n",
    "                valid_err_num, valid_err_den = report_err_rate(target_valid, forward_valid)\n",
    "                valid_err_rate_num = torch.cat((valid_err_rate_num, (valid_err_num.view(1,-1))**2), 0)\n",
    "                valid_err_rate_den = torch.cat((valid_err_rate_den, (valid_err_den.view(1,-1))**2), 0)\n",
    "\n",
    "            valid_loss = torch.mean(valid_loss_array)\n",
    "            valid_err_rate = 100*((torch.sum(valid_err_rate_num, 0))**0.5)/((torch.sum(valid_err_rate_den, 0))**0.5)\n",
    "\n",
    "        verb = True if (epoch >= 50) and (epoch % 10 == 0) else False\n",
    "        if (verb):\n",
    "            train_loss_hist = torch.cat((train_loss_hist, torch.cuda.FloatTensor([[train_loss]])))\n",
    "            train_err_hist = torch.cat((train_err_hist, train_err_rate.view(1,-1)), 0)\n",
    "            valid_loss_hist = torch.cat((valid_loss_hist, torch.cuda.FloatTensor([[valid_loss]])))\n",
    "            valid_err_hist = torch.cat((valid_err_hist, valid_err_rate.view(1,-1)), 0)\n",
    "        verb = True if (epoch % 50 == 0) else False\n",
    "        if (verb) :\n",
    "            print('{:4}   lr: {:.2e}   train_loss: {:.2e}   valid_loss: {:.2e}   train_error:{:7.2f}%   valid_error:{:7.2f}%' \\\n",
    "                  .format(epoch, exp_lr_scheduler.get_lr()[0], train_loss, valid_loss, train_err_rate[0], valid_err_rate[0]))\n",
    "            \n",
    "    print('Finished Training')\n",
    "    return train_loss_hist, train_err_hist, valid_loss_hist, valid_err_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bef76b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_err_rate(target, forward):\n",
    "    errRate_sigma_num = torch.norm(forward - target, dim = 0)\n",
    "    errRate_sigma_den = torch.norm(target, dim = 0)\n",
    "    return errRate_sigma_num, errRate_sigma_den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2d5fa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_plot(training_loss_history, training_error_history, valid_loss_history, valid_error_history):\n",
    "    \n",
    "    data1 = go.Scatter(x=np.arange(50,num_epoch+1,10), y=training_loss_history[1:,0], line = dict(width=1.7), name = 'Training Loss', mode = 'lines')\n",
    "    data2 = go.Scatter(x=np.arange(50,num_epoch+1,10), y=valid_loss_history[1:,0], line = dict(width=1.7), name = 'Validation Loss', mode = 'lines')\n",
    "    data3 = go.Scatter(x=np.arange(50,num_epoch+1,10), y=training_error_history[1:,0], line = dict(width=1.7), name = 'Training Error', mode = 'lines')\n",
    "    data4 = go.Scatter(x=np.arange(50,num_epoch+1,10), y=valid_error_history[1:,0], line = dict(width=1.7), name = 'Validation Error', mode = 'lines')\n",
    "    \n",
    "    fig = subplots.make_subplots(rows=1, cols=2)\n",
    "    fig.append_trace(data1, 1, 1)\n",
    "    fig.append_trace(data2, 1, 1)\n",
    "    fig.append_trace(data3, 1, 2)\n",
    "    fig.append_trace(data4, 1, 2)\n",
    "    \n",
    "    fig['layout']['xaxis1'].update(title='Epochs', showgrid=True, gridwidth=0.5, gridcolor='lightgrey', showline=True, linecolor='black')\n",
    "    fig['layout']['yaxis1'].update(title='Loss', showgrid=True, gridwidth=0.5, gridcolor='lightgrey', showline=True, linecolor='black')\n",
    "    fig['layout']['xaxis2'].update(title='Epochs', showgrid=True, gridwidth=0.5, gridcolor='lightgrey', showline=True, linecolor='black')\n",
    "    fig['layout']['yaxis2'].update(title='Error %', showgrid=True, gridwidth=0.5, gridcolor='lightgrey', showline=True, linecolor='black')\n",
    "    fig['layout'].update(height=450, width=1000, plot_bgcolor = 'rgba(0,0,0,0)', title='Loss and Error Percentage History')\n",
    "    iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd29a44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=torch.device('cuda:0')\n",
    "else:\n",
    "    device=torch.device('cpu')\n",
    "\n",
    "device_cpu = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5dae599",
   "metadata": {},
   "outputs": [],
   "source": [
    "stencil_size = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d50c3dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX_train = torch.load('new_dataX_train.pt')\n",
    "dataY_train = torch.load('new_dataY_train.pt')\n",
    "dataX_valid = torch.load('new_dataX_valid.pt')\n",
    "dataY_valid = torch.load('new_dataY_valid.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7f6a9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stencil size: 150 \n",
      "train: Input:torch.Size([1260000, 150, 11])  Label:torch.Size([1260000, 1]) \n",
      "valid: Input:torch.Size([20000, 150, 11])  Label:torch.Size([20000, 1])\n"
     ]
    }
   ],
   "source": [
    "print('stencil size: {} \\ntrain: Input:{}  Label:{} \\nvalid: Input:{}  Label:{}' \\\n",
    "      .format(stencil_size,dataX_train.shape,dataY_train.shape,dataX_valid.shape,dataY_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6d92f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX_train = dataX_train.to(device)\n",
    "dataY_train = dataY_train.to(device)\n",
    "dataX_valid = dataX_valid.to(device)\n",
    "dataY_valid = dataY_valid.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fc5c05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating datasets\n",
    "dataset_train = TensorDataset(dataX_train,dataY_train)\n",
    "dataset_valid = TensorDataset(dataX_valid,dataY_valid)\n",
    "\n",
    "#creating batches from dataset\n",
    "batch_size_train = 1024        \n",
    "batch_size_valid = dataX_valid.shape[0]\n",
    "\n",
    "train_loader = DataLoader(dataset = dataset_train, batch_size=batch_size_train, shuffle=True)\n",
    "valid_loader = DataLoader(dataset = dataset_valid, batch_size=batch_size_valid, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2206a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "model = Net()\n",
    "model.to(device)\n",
    "loss_fn = nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d707efec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Learnable Parameters: 39553\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "para_count = count_parameters(model)\n",
    "print('Total Learnable Parameters: {}'.format(para_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "974bf765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "num_epoch = 2000\n",
    "learning_rate = 1e-3\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=600, gamma=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9659e902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuhuizhou/miniconda3/envs/torch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0   lr: 1.00e-03   train_loss: 3.24e+00   valid_loss: 1.56e-01   train_error:  13.27%   valid_error:   7.41%\n",
      "  50   lr: 1.00e-03   train_loss: 3.04e-02   valid_loss: 6.88e-03   train_error:   1.29%   valid_error:   3.93%\n",
      " 100   lr: 1.00e-03   train_loss: 1.68e-02   valid_loss: 4.31e-03   train_error:   0.96%   valid_error:   3.55%\n",
      " 150   lr: 1.00e-03   train_loss: 1.22e-02   valid_loss: 2.89e-03   train_error:   0.81%   valid_error:   3.18%\n",
      " 200   lr: 1.00e-03   train_loss: 9.66e-03   valid_loss: 2.25e-03   train_error:   0.72%   valid_error:   3.25%\n",
      " 250   lr: 1.00e-03   train_loss: 8.17e-03   valid_loss: 2.73e-03   train_error:   0.67%   valid_error:   3.34%\n",
      " 300   lr: 1.00e-03   train_loss: 7.18e-03   valid_loss: 1.54e-03   train_error:   0.63%   valid_error:   3.16%\n",
      " 350   lr: 1.00e-03   train_loss: 6.57e-03   valid_loss: 1.48e-03   train_error:   0.60%   valid_error:   3.38%\n",
      " 400   lr: 1.00e-03   train_loss: 6.06e-03   valid_loss: 1.21e-03   train_error:   0.57%   valid_error:   3.15%\n",
      " 450   lr: 1.00e-03   train_loss: 5.76e-03   valid_loss: 1.45e-03   train_error:   0.56%   valid_error:   3.15%\n",
      " 500   lr: 1.00e-03   train_loss: 5.36e-03   valid_loss: 1.37e-03   train_error:   0.54%   valid_error:   3.10%\n",
      " 550   lr: 1.00e-03   train_loss: 5.09e-03   valid_loss: 1.07e-03   train_error:   0.53%   valid_error:   3.11%\n",
      " 600   lr: 7.00e-04   train_loss: 4.22e-03   valid_loss: 1.33e-03   train_error:   0.48%   valid_error:   3.01%\n",
      " 650   lr: 7.00e-04   train_loss: 4.18e-03   valid_loss: 8.10e-04   train_error:   0.48%   valid_error:   2.92%\n",
      " 700   lr: 7.00e-04   train_loss: 4.11e-03   valid_loss: 9.95e-04   train_error:   0.47%   valid_error:   3.28%\n",
      " 750   lr: 7.00e-04   train_loss: 3.95e-03   valid_loss: 8.23e-04   train_error:   0.46%   valid_error:   3.01%\n",
      " 800   lr: 7.00e-04   train_loss: 3.91e-03   valid_loss: 9.49e-04   train_error:   0.46%   valid_error:   2.93%\n",
      " 850   lr: 7.00e-04   train_loss: 3.82e-03   valid_loss: 9.86e-04   train_error:   0.46%   valid_error:   3.03%\n",
      " 900   lr: 7.00e-04   train_loss: 3.79e-03   valid_loss: 7.14e-04   train_error:   0.45%   valid_error:   3.20%\n",
      " 950   lr: 7.00e-04   train_loss: 3.71e-03   valid_loss: 9.95e-04   train_error:   0.45%   valid_error:   2.92%\n",
      "1000   lr: 7.00e-04   train_loss: 3.66e-03   valid_loss: 8.47e-04   train_error:   0.45%   valid_error:   2.94%\n",
      "1050   lr: 7.00e-04   train_loss: 3.62e-03   valid_loss: 7.35e-04   train_error:   0.44%   valid_error:   2.97%\n",
      "1100   lr: 7.00e-04   train_loss: 3.57e-03   valid_loss: 8.30e-04   train_error:   0.44%   valid_error:   2.97%\n",
      "1150   lr: 7.00e-04   train_loss: 3.49e-03   valid_loss: 1.06e-03   train_error:   0.44%   valid_error:   3.02%\n",
      "1200   lr: 4.90e-04   train_loss: 3.06e-03   valid_loss: 6.31e-04   train_error:   0.41%   valid_error:   3.00%\n",
      "1250   lr: 4.90e-04   train_loss: 3.08e-03   valid_loss: 7.92e-04   train_error:   0.41%   valid_error:   3.02%\n",
      "1300   lr: 4.90e-04   train_loss: 3.09e-03   valid_loss: 5.04e-04   train_error:   0.41%   valid_error:   3.01%\n",
      "1350   lr: 4.90e-04   train_loss: 3.09e-03   valid_loss: 7.18e-04   train_error:   0.41%   valid_error:   3.01%\n",
      "1400   lr: 4.90e-04   train_loss: 3.03e-03   valid_loss: 6.77e-04   train_error:   0.41%   valid_error:   3.09%\n",
      "1450   lr: 4.90e-04   train_loss: 2.99e-03   valid_loss: 7.70e-04   train_error:   0.40%   valid_error:   3.12%\n",
      "1500   lr: 4.90e-04   train_loss: 2.97e-03   valid_loss: 7.02e-04   train_error:   0.40%   valid_error:   2.98%\n",
      "1550   lr: 4.90e-04   train_loss: 2.93e-03   valid_loss: 6.77e-04   train_error:   0.40%   valid_error:   2.98%\n",
      "1600   lr: 4.90e-04   train_loss: 2.95e-03   valid_loss: 6.20e-04   train_error:   0.40%   valid_error:   3.15%\n",
      "1650   lr: 4.90e-04   train_loss: 2.91e-03   valid_loss: 6.85e-04   train_error:   0.40%   valid_error:   3.12%\n",
      "1700   lr: 4.90e-04   train_loss: 2.90e-03   valid_loss: 6.42e-04   train_error:   0.40%   valid_error:   3.19%\n",
      "1750   lr: 4.90e-04   train_loss: 2.88e-03   valid_loss: 7.78e-04   train_error:   0.40%   valid_error:   3.26%\n",
      "1800   lr: 3.43e-04   train_loss: 2.62e-03   valid_loss: 7.32e-04   train_error:   0.38%   valid_error:   3.24%\n",
      "1850   lr: 3.43e-04   train_loss: 2.67e-03   valid_loss: 5.52e-04   train_error:   0.38%   valid_error:   3.19%\n",
      "1900   lr: 3.43e-04   train_loss: 2.63e-03   valid_loss: 7.53e-04   train_error:   0.38%   valid_error:   3.24%\n",
      "1950   lr: 3.43e-04   train_loss: 2.64e-03   valid_loss: 5.69e-04   train_error:   0.38%   valid_error:   3.19%\n",
      "2000   lr: 3.43e-04   train_loss: 2.61e-03   valid_loss: 6.27e-04   train_error:   0.38%   valid_error:   3.31%\n",
      "Finished Training\n",
      "Training time: 66898.0 s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "training_loss_history, training_error_history, valid_loss_history, valid_error_history = train(train_loader, valid_loader, num_epoch)\n",
    "elapsed = time.time() - start_time                \n",
    "print('Training time: %.1f s' % (elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2dfad959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'test1_gpu.pt')\n",
    "model.to(device_cpu)\n",
    "torch.save(model, 'parametric_study_4_cpu.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ecd886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
